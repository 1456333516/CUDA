// =====================================================================
// CUDA归约操作 - 静态共享内存版本 (CUDA初学者详细教程)
// =====================================================================

// 条件编译：这是一个重要的编程技巧，让我们可以根据需要选择不同的数据精度
#ifdef USE_DP
    // 如果定义了USE_DP宏，就使用双精度浮点数
    typedef double real;           // double类型占用64位，精度更高但速度稍慢
    const real EPSILON = 1.0e-15;  // 双精度下的极小值，用于比较两个浮点数是否相等
#else
    // 如果没有定义USE_DP宏，就使用单精度浮点数（默认情况）
    typedef float real;            // float类型占用32位，速度快但精度较低
    const real EPSILON = 1.0e-6;   // 单精度下的极小值，用于浮点数比较
#endif

// =====================================================================
// CUDA内核函数：使用共享内存的归约操作（求和）
// 这比全局内存版本更快，因为共享内存访问速度远超全局内存
// =====================================================================
void __global__ reduce_shared(real *d_x, real *d_y)
{
    // 获取当前线程在块内的编号（0到blockDim.x-1）
    // 比如在一个128线程的块中，tid的值就是0,1,2,...,127
    const int tid = threadIdx.x;
    
    // 获取当前线程块的编号（在整个网格中的位置）
    // 如果有多个块，bid用来区分不同的块
    const int bid = blockIdx.x;
    
    // 计算当前线程要处理的全局数组元素索引
    // 注意：这里有拼写错误，应该是blockDim.x而不是blockDin.x
    const int n = bid * blockDim.x + tid;
    
    // ================================================================
    // 共享内存声明：这是这个版本的关键优化点！
    // __shared__关键字告诉CUDA这是块内所有线程共享的内存
    // 访问速度比全局内存快100倍以上
    // ================================================================
    __shared__ real s_y[128];  // 声明大小为128的共享内存数组
    
    // 将全局内存的数据加载到共享内存中
    // 条件表达式：如果n在有效范围内就复制数据，否则填充0
    // 这样处理边界情况，避免访问非法内存
    s_y[tid] = (n < N) ? d_x[n] : 0.0;
    
    // 非常重要的同步点！
    // 确保所有线程都完成了数据从全局内存到共享内存的加载
    // 然后才能开始归约计算
    __syncthreads();

    // ================================================================
    // 归约算法核心部分：在共享内存中进行树形归约
    // 这是最高效的并行归约方法
    // ================================================================
    
    // offset从线程块大小的一半开始，每次减半
    // 注意：这里同样有拼写错误，应该是blockDim.x
    for(int offset = blockDim.x >> 1; offset > 0; offset >>= 1)
    {
        // 只有编号小于offset的线程才参与这次归约
        // 这样可以避免数组越界访问，同时减少不必要的计算
        if(tid < offset)
        {
            // 核心归约操作：将两个元素相加
            // 这里是在共享内存中操作，速度非常快！
            s_y[tid] += s_y[tid + offset];
        }
        
        // 每次归约操作后的必要同步
        // 确保所有线程都完成了当前步骤的计算
        // 然后才能进行下一步归约
        __syncthreads();
    }
    
    // 当归约完成后，只有编号为0的线程负责将结果写回全局内存
    // 这样避免了多个线程同时写入同一位置的竞争问题
    if(tid == 0)
    {
        // 将当前块的归约结果存储到输出数组对应位置
        // d_y[bid]表示第bid个块的结果存储在d_y数组的第bid个位置
        d_y[bid] = s_y[0];  // s_y[0]现在包含了这个块所有元素的和
    }
}

// =====================================================================
// 算法工作原理详细说明（假设blockDim.x = 8）:
//
// 步骤1：数据加载阶段
// 全局内存: [1][2][3][4][5][6][7][8][9][10]...
// 共享内存: [1][2][3][4][5][6][7][8] (前8个元素)
//
// 步骤2：第一轮归约 (offset=4)
// 共享内存变化: [1+5][2+6][3+7][4+8][5][6][7][8]
// 结果: [6][8][10][12][5][6][7][8]
//
// 步骤3：第二轮归约 (offset=2)
// 共享内存变化: [6+10][8+12][10][12][5][6][7][8]
// 结果: [16][20][10][12][5][6][7][8]
//
// 步骤4：第三轮归约 (offset=1)
// 共享内存变化: [16+20][20][10][12][5][6][7][8]
// 结果: [36][20][10][12][5][6][7][8]
//
// 步骤5：结果输出
// 线程0将s_y[0]=36写入d_y[bid]
// =====================================================================

// =====================================================================
// 性能优势说明：
// 1. 共享内存访问速度比全局内存快约100倍
// 2. 减少了全局内存访问次数
// 3. 数据重用率高，每个元素只需要加载一次
// 4. 避免了内存带宽瓶颈
// =====================================================================